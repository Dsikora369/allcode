{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"CIFAR-10.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN2YDSLCi/W3tv2tM3KIwz7"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ftcKTWvoTTyj"},"source":["##1. Downloading data and preprocessing##"]},{"cell_type":"code","metadata":{"id":"qWbfEG5KTMgi"},"source":["import tensorflow as tf\n","\n","from tensorflow.keras import datasets, layers, models\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wKL5yEADTk6L","executionInfo":{"status":"ok","timestamp":1622321068692,"user_tz":-180,"elapsed":4363,"user":{"displayName":"Denis Sikorskii","photoUrl":"","userId":"12474883084875338206"}},"outputId":"87174b9f-4907-4c47-b63f-9083754d45e6"},"source":["(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n","\n","# Normalize pixel values to be between 0 and 1\n","train_images, test_images = train_images / 255.0, test_images / 255.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 2s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xzl33NfbTzt7"},"source":["##2. Checking photos for conformity with labels##"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":231},"id":"zgk5xzb1UFQI","executionInfo":{"status":"error","timestamp":1624551026594,"user_tz":-180,"elapsed":6,"user":{"displayName":"Denis Sikorskii","photoUrl":"","userId":"12474883084875338206"}},"outputId":"7dced647-4025-42ab-d096-1071985e0089"},"source":["class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n","               'dog', 'frog', 'horse', 'ship', 'truck']\n","\n","plt.figure(figsize=(10,10))\n","\n","\n","for i in range(25):\n","    plt.subplot(5,5,i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    plt.imshow(train_images[i])\n","    plt.xlabel(class_names[train_labels[i][0]])\n","\n","\n","plt.show()"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-8ba2d87c40f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                'dog', 'frog', 'horse', 'ship', 'truck']\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"UKvPplQiUaSy"},"source":["As we can see all labels are correct, so we can proceed."]},{"cell_type":"markdown","metadata":{"id":"6cvN4sE7UiuL"},"source":["##3. Creating simple neural network##"]},{"cell_type":"markdown","metadata":{"id":"z5AO9DepU16k"},"source":["**Transforming photos to grayscale**"]},{"cell_type":"code","metadata":{"id":"RPKNW2EvVtEa"},"source":["train_images = tf.image.rgb_to_grayscale(train_images, name=None)\n","test_images = tf.image.rgb_to_grayscale(test_images, name=None)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WwC2ZHdJYyt5"},"source":["**Creating and training model**"]},{"cell_type":"code","metadata":{"id":"zZtRe1LoVElh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622321204106,"user_tz":-180,"elapsed":125933,"user":{"displayName":"Denis Sikorskii","photoUrl":"","userId":"12474883084875338206"}},"outputId":"305979be-bf3b-42d7-b631-29d14db4538c"},"source":["model = tf.keras.models.Sequential([\n","                        tf.keras.layers.Flatten(),  # transform matrix into vector \n","                        tf.keras.layers.Dense(32*32, activation='relu'),\n","                        tf.keras.layers.Dense(128, activation='relu'),\n","                        tf.keras.layers.Dense(64, activation='relu'),\n","                        tf.keras.layers.Dense(10, activation='softmax')])\n","model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","history = model.fit(train_images, train_labels, epochs=20, \n","                    validation_data=(test_images, test_labels))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:4930: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n","  '\"`sparse_categorical_crossentropy` received `from_logits=True`, but '\n"],"name":"stderr"},{"output_type":"stream","text":["1563/1563 [==============================] - 5s 3ms/step - loss: 2.0491 - accuracy: 0.2503 - val_loss: 1.9444 - val_accuracy: 0.2920\n","Epoch 2/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.9023 - accuracy: 0.3140 - val_loss: 1.8482 - val_accuracy: 0.3359\n","Epoch 3/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.8337 - accuracy: 0.3418 - val_loss: 1.8214 - val_accuracy: 0.3497\n","Epoch 4/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.7884 - accuracy: 0.3597 - val_loss: 1.8054 - val_accuracy: 0.3527\n","Epoch 5/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.7502 - accuracy: 0.3726 - val_loss: 1.7994 - val_accuracy: 0.3526\n","Epoch 6/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.7282 - accuracy: 0.3821 - val_loss: 1.7449 - val_accuracy: 0.3747\n","Epoch 7/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.7002 - accuracy: 0.3908 - val_loss: 1.7372 - val_accuracy: 0.3775\n","Epoch 8/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.6757 - accuracy: 0.4009 - val_loss: 1.7138 - val_accuracy: 0.3847\n","Epoch 9/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.6582 - accuracy: 0.4069 - val_loss: 1.6739 - val_accuracy: 0.4027\n","Epoch 10/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.6312 - accuracy: 0.4162 - val_loss: 1.7478 - val_accuracy: 0.3770\n","Epoch 11/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.6167 - accuracy: 0.4244 - val_loss: 1.6815 - val_accuracy: 0.3998\n","Epoch 12/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.5975 - accuracy: 0.4308 - val_loss: 1.6578 - val_accuracy: 0.4085\n","Epoch 13/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.5810 - accuracy: 0.4369 - val_loss: 1.7035 - val_accuracy: 0.3833\n","Epoch 14/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.5658 - accuracy: 0.4404 - val_loss: 1.6511 - val_accuracy: 0.4102\n","Epoch 15/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.5530 - accuracy: 0.4468 - val_loss: 1.6694 - val_accuracy: 0.4044\n","Epoch 16/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.5391 - accuracy: 0.4520 - val_loss: 1.6850 - val_accuracy: 0.4067\n","Epoch 17/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.5295 - accuracy: 0.4570 - val_loss: 1.6481 - val_accuracy: 0.4125\n","Epoch 18/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.5135 - accuracy: 0.4627 - val_loss: 1.6638 - val_accuracy: 0.4093\n","Epoch 19/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.4996 - accuracy: 0.4666 - val_loss: 1.6579 - val_accuracy: 0.4123\n","Epoch 20/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.4886 - accuracy: 0.4698 - val_loss: 1.6723 - val_accuracy: 0.4127\n","Epoch 21/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.4772 - accuracy: 0.4759 - val_loss: 1.6618 - val_accuracy: 0.4124\n","Epoch 22/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.4705 - accuracy: 0.4768 - val_loss: 1.6455 - val_accuracy: 0.4179\n","Epoch 23/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.4564 - accuracy: 0.4802 - val_loss: 1.6783 - val_accuracy: 0.4096\n","Epoch 24/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.4471 - accuracy: 0.4864 - val_loss: 1.6512 - val_accuracy: 0.4149\n","Epoch 25/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.4386 - accuracy: 0.4871 - val_loss: 1.6809 - val_accuracy: 0.4140\n","Epoch 26/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.4273 - accuracy: 0.4922 - val_loss: 1.7154 - val_accuracy: 0.3974\n","Epoch 27/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.4227 - accuracy: 0.4943 - val_loss: 1.6764 - val_accuracy: 0.4132\n","Epoch 28/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.4112 - accuracy: 0.4966 - val_loss: 1.7016 - val_accuracy: 0.4071\n","Epoch 29/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.4045 - accuracy: 0.4990 - val_loss: 1.6846 - val_accuracy: 0.4162\n","Epoch 30/30\n","1563/1563 [==============================] - 4s 3ms/step - loss: 1.3938 - accuracy: 0.5030 - val_loss: 1.6912 - val_accuracy: 0.4128\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iHZ1xaTmbo2T"},"source":["As we can see simple neural network achieved only about 41% accuracy on validation, so it can't be called efficient solution."]},{"cell_type":"markdown","metadata":{"id":"fD3E1HZ1cJ5p"},"source":["##4. Creating CNN ##"]},{"cell_type":"code","metadata":{"id":"RopL50LudORM"},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.optimizers import SGD\n","from tensorflow.keras.utils import to_categorical\n","from keras import regularizers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BPb-D5cGcYID"},"source":["(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n","train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)\n","train_images, test_images = train_images / 255.0, test_images / 255.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ABxaiiVcOz9","executionInfo":{"status":"ok","timestamp":1622321504103,"user_tz":-180,"elapsed":298797,"user":{"displayName":"Denis Sikorskii","photoUrl":"","userId":"12474883084875338206"}},"outputId":"5fc4eafb-92ff-4aeb-e690-fb5bafcfee66"},"source":["model = models.Sequential()\n","\n","model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n","model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(10, activation='softmax'))\n","# compile model\n","opt = SGD(lr=0.001, momentum=0.9)\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","history = model.fit(train_images, train_labels, epochs=10, \n","                    validation_data=(test_images, test_labels))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n","1563/1563 [==============================] - 57s 18ms/step - loss: 1.7910 - accuracy: 0.3572 - val_loss: 1.5529 - val_accuracy: 0.4545\n","Epoch 2/10\n","1563/1563 [==============================] - 28s 18ms/step - loss: 1.4482 - accuracy: 0.4802 - val_loss: 1.3571 - val_accuracy: 0.5087\n","Epoch 3/10\n","1563/1563 [==============================] - 26s 17ms/step - loss: 1.2717 - accuracy: 0.5429 - val_loss: 1.1960 - val_accuracy: 0.5701\n","Epoch 4/10\n","1563/1563 [==============================] - 26s 17ms/step - loss: 1.1126 - accuracy: 0.6033 - val_loss: 1.1179 - val_accuracy: 0.6011\n","Epoch 5/10\n","1563/1563 [==============================] - 26s 17ms/step - loss: 0.9575 - accuracy: 0.6597 - val_loss: 1.0872 - val_accuracy: 0.6171\n","Epoch 6/10\n","1563/1563 [==============================] - 27s 17ms/step - loss: 0.8095 - accuracy: 0.7116 - val_loss: 1.0219 - val_accuracy: 0.6444\n","Epoch 7/10\n","1563/1563 [==============================] - 27s 17ms/step - loss: 0.6387 - accuracy: 0.7757 - val_loss: 1.0899 - val_accuracy: 0.6435\n","Epoch 8/10\n","1563/1563 [==============================] - 27s 17ms/step - loss: 0.4463 - accuracy: 0.8436 - val_loss: 1.1717 - val_accuracy: 0.6474\n","Epoch 9/10\n","1563/1563 [==============================] - 27s 17ms/step - loss: 0.2817 - accuracy: 0.9025 - val_loss: 1.4670 - val_accuracy: 0.6376\n","Epoch 10/10\n","1563/1563 [==============================] - 27s 17ms/step - loss: 0.1702 - accuracy: 0.9414 - val_loss: 1.6707 - val_accuracy: 0.6396\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7DLhkwkKkNn_"},"source":["After comparing test and val losses it is obvious that overtraining has occurred."]},{"cell_type":"markdown","metadata":{"id":"f6pfMN7_knL4"},"source":["##5. Adding Dropout and BatchNormalization"]},{"cell_type":"markdown","metadata":{"id":"9jabv01Q1OFn"},"source":["Also, let's change activation function for elu, batch size, and add weight decay."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tdpZAKexz22I","executionInfo":{"status":"ok","timestamp":1622327067553,"user_tz":-180,"elapsed":864643,"user":{"displayName":"Denis Sikorskii","photoUrl":"","userId":"12474883084875338206"}},"outputId":"088a8bde-6e50-49f3-a89d-50ea6f9e85fb"},"source":["weight_decay = 1e-4 # adding weight decay to decrease learning rate after few iterations\n","model = Sequential()\n","model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=(32, 32, 3)))\n","model.add(Activation('elu')) # changing 'relu' to 'elu' for better perfomance\n","model.add(BatchNormalization()) # adding BatchNormalization\n","model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2))) # adding MaxPooling for better extraction of features\n","model.add(Dropout(0.3)) # adding Dropout to fight overfitting\n","\n","model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.4))\n","\n","model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.5))\n","model.add(Flatten())\n","model.add(Dense(128, activation='elu'))\n","model.add(Dense(10, activation='softmax'))\n","\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","history = model.fit(train_images, train_labels, epochs=100, batch_size = 64, \n","                    validation_data=(test_images, test_labels))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","782/782 [==============================] - 12s 12ms/step - loss: 2.1765 - accuracy: 0.3063 - val_loss: 1.6595 - val_accuracy: 0.4322\n","Epoch 2/100\n","782/782 [==============================] - 8s 10ms/step - loss: 1.4833 - accuracy: 0.4695 - val_loss: 1.3743 - val_accuracy: 0.5186\n","Epoch 3/100\n","782/782 [==============================] - 8s 10ms/step - loss: 1.3478 - accuracy: 0.5255 - val_loss: 1.2644 - val_accuracy: 0.5673\n","Epoch 4/100\n","782/782 [==============================] - 8s 10ms/step - loss: 1.2182 - accuracy: 0.5758 - val_loss: 1.2123 - val_accuracy: 0.5856\n","Epoch 5/100\n","782/782 [==============================] - 8s 10ms/step - loss: 1.1202 - accuracy: 0.6120 - val_loss: 1.0432 - val_accuracy: 0.6458\n","Epoch 6/100\n","782/782 [==============================] - 8s 10ms/step - loss: 1.0509 - accuracy: 0.6381 - val_loss: 0.9747 - val_accuracy: 0.6726\n","Epoch 7/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.9931 - accuracy: 0.6594 - val_loss: 0.9507 - val_accuracy: 0.6756\n","Epoch 8/100\n","782/782 [==============================] - 9s 11ms/step - loss: 0.9529 - accuracy: 0.6738 - val_loss: 0.9025 - val_accuracy: 0.6964\n","Epoch 9/100\n","782/782 [==============================] - 9s 11ms/step - loss: 0.9153 - accuracy: 0.6885 - val_loss: 0.8762 - val_accuracy: 0.7078\n","Epoch 10/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.8854 - accuracy: 0.6989 - val_loss: 0.8522 - val_accuracy: 0.7128\n","Epoch 11/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.8664 - accuracy: 0.7050 - val_loss: 0.8693 - val_accuracy: 0.7097\n","Epoch 12/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.8438 - accuracy: 0.7145 - val_loss: 0.8470 - val_accuracy: 0.7176\n","Epoch 13/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.8203 - accuracy: 0.7205 - val_loss: 0.8009 - val_accuracy: 0.7352\n","Epoch 14/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.8100 - accuracy: 0.7253 - val_loss: 0.7765 - val_accuracy: 0.7446\n","Epoch 15/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.7869 - accuracy: 0.7332 - val_loss: 0.7444 - val_accuracy: 0.7538\n","Epoch 16/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.7735 - accuracy: 0.7414 - val_loss: 0.7655 - val_accuracy: 0.7474\n","Epoch 17/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.7530 - accuracy: 0.7472 - val_loss: 0.7353 - val_accuracy: 0.7557\n","Epoch 18/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.7372 - accuracy: 0.7521 - val_loss: 0.7097 - val_accuracy: 0.7671\n","Epoch 19/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.7301 - accuracy: 0.7533 - val_loss: 0.7193 - val_accuracy: 0.7613\n","Epoch 20/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.7155 - accuracy: 0.7586 - val_loss: 0.7090 - val_accuracy: 0.7649\n","Epoch 21/100\n","782/782 [==============================] - 9s 11ms/step - loss: 0.7028 - accuracy: 0.7657 - val_loss: 0.6885 - val_accuracy: 0.7725\n","Epoch 22/100\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6938 - accuracy: 0.7696 - val_loss: 0.7099 - val_accuracy: 0.7664\n","Epoch 23/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.6715 - accuracy: 0.7752 - val_loss: 0.6644 - val_accuracy: 0.7839\n","Epoch 24/100\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6609 - accuracy: 0.7769 - val_loss: 0.6611 - val_accuracy: 0.7838\n","Epoch 25/100\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6644 - accuracy: 0.7786 - val_loss: 0.6899 - val_accuracy: 0.7741\n","Epoch 26/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.6490 - accuracy: 0.7806 - val_loss: 0.6548 - val_accuracy: 0.7851\n","Epoch 27/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.6407 - accuracy: 0.7863 - val_loss: 0.6684 - val_accuracy: 0.7787\n","Epoch 28/100\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6347 - accuracy: 0.7889 - val_loss: 0.6605 - val_accuracy: 0.7804\n","Epoch 29/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.6220 - accuracy: 0.7903 - val_loss: 0.6299 - val_accuracy: 0.7938\n","Epoch 30/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.6082 - accuracy: 0.7975 - val_loss: 0.6454 - val_accuracy: 0.7902\n","Epoch 31/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.6107 - accuracy: 0.7951 - val_loss: 0.6239 - val_accuracy: 0.7974\n","Epoch 32/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.5975 - accuracy: 0.7993 - val_loss: 0.6182 - val_accuracy: 0.7998\n","Epoch 33/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.5834 - accuracy: 0.8049 - val_loss: 0.6379 - val_accuracy: 0.7945\n","Epoch 34/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.5805 - accuracy: 0.8032 - val_loss: 0.6683 - val_accuracy: 0.7837\n","Epoch 35/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.5727 - accuracy: 0.8090 - val_loss: 0.5993 - val_accuracy: 0.8057\n","Epoch 36/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.5636 - accuracy: 0.8129 - val_loss: 0.5955 - val_accuracy: 0.8078\n","Epoch 37/100\n","782/782 [==============================] - 8s 11ms/step - loss: 0.5516 - accuracy: 0.8168 - val_loss: 0.6156 - val_accuracy: 0.8014\n","Epoch 38/100\n","782/782 [==============================] - 8s 11ms/step - loss: 0.5468 - accuracy: 0.8191 - val_loss: 0.5928 - val_accuracy: 0.8123\n","Epoch 39/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.5435 - accuracy: 0.8216 - val_loss: 0.5810 - val_accuracy: 0.8130\n","Epoch 40/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.5283 - accuracy: 0.8286 - val_loss: 0.6001 - val_accuracy: 0.8074\n","Epoch 41/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.5252 - accuracy: 0.8261 - val_loss: 0.5816 - val_accuracy: 0.8142\n","Epoch 42/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.5203 - accuracy: 0.8283 - val_loss: 0.5881 - val_accuracy: 0.8131\n","Epoch 43/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.5179 - accuracy: 0.8316 - val_loss: 0.5769 - val_accuracy: 0.8144\n","Epoch 44/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.5081 - accuracy: 0.8303 - val_loss: 0.5545 - val_accuracy: 0.8201\n","Epoch 45/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.4979 - accuracy: 0.8354 - val_loss: 0.5739 - val_accuracy: 0.8195\n","Epoch 46/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.4962 - accuracy: 0.8371 - val_loss: 0.5730 - val_accuracy: 0.8193\n","Epoch 47/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.4899 - accuracy: 0.8362 - val_loss: 0.5553 - val_accuracy: 0.8225\n","Epoch 48/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.4868 - accuracy: 0.8393 - val_loss: 0.5617 - val_accuracy: 0.8225\n","Epoch 49/100\n","782/782 [==============================] - 9s 11ms/step - loss: 0.4810 - accuracy: 0.8450 - val_loss: 0.5729 - val_accuracy: 0.8189\n","Epoch 50/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.4616 - accuracy: 0.8480 - val_loss: 0.5724 - val_accuracy: 0.8230\n","Epoch 51/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.4737 - accuracy: 0.8455 - val_loss: 0.5556 - val_accuracy: 0.8235\n","Epoch 52/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.4663 - accuracy: 0.8445 - val_loss: 0.5514 - val_accuracy: 0.8252\n","Epoch 53/100\n","782/782 [==============================] - 9s 11ms/step - loss: 0.4547 - accuracy: 0.8508 - val_loss: 0.5739 - val_accuracy: 0.8219\n","Epoch 54/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.4537 - accuracy: 0.8547 - val_loss: 0.5446 - val_accuracy: 0.8307\n","Epoch 55/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.4423 - accuracy: 0.8545 - val_loss: 0.5576 - val_accuracy: 0.8248\n","Epoch 56/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.4448 - accuracy: 0.8531 - val_loss: 0.5374 - val_accuracy: 0.8305\n","Epoch 57/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.4439 - accuracy: 0.8549 - val_loss: 0.5496 - val_accuracy: 0.8299\n","Epoch 58/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.4301 - accuracy: 0.8601 - val_loss: 0.5371 - val_accuracy: 0.8331\n","Epoch 59/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.4318 - accuracy: 0.8612 - val_loss: 0.5569 - val_accuracy: 0.8268\n","Epoch 60/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.4187 - accuracy: 0.8626 - val_loss: 0.5520 - val_accuracy: 0.8279\n","Epoch 61/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.4187 - accuracy: 0.8639 - val_loss: 0.5392 - val_accuracy: 0.8351\n","Epoch 62/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.4176 - accuracy: 0.8646 - val_loss: 0.5329 - val_accuracy: 0.8371\n","Epoch 63/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.4111 - accuracy: 0.8650 - val_loss: 0.5268 - val_accuracy: 0.8390\n","Epoch 64/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.4073 - accuracy: 0.8670 - val_loss: 0.5354 - val_accuracy: 0.8378\n","Epoch 65/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3970 - accuracy: 0.8742 - val_loss: 0.5477 - val_accuracy: 0.8325\n","Epoch 66/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3981 - accuracy: 0.8702 - val_loss: 0.5340 - val_accuracy: 0.8380\n","Epoch 67/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3941 - accuracy: 0.8711 - val_loss: 0.5413 - val_accuracy: 0.8345\n","Epoch 68/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3831 - accuracy: 0.8763 - val_loss: 0.5295 - val_accuracy: 0.8411\n","Epoch 69/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3819 - accuracy: 0.8756 - val_loss: 0.5718 - val_accuracy: 0.8259\n","Epoch 70/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3806 - accuracy: 0.8771 - val_loss: 0.5409 - val_accuracy: 0.8383\n","Epoch 71/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3644 - accuracy: 0.8837 - val_loss: 0.5434 - val_accuracy: 0.8349\n","Epoch 72/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3683 - accuracy: 0.8812 - val_loss: 0.5458 - val_accuracy: 0.8344\n","Epoch 73/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3597 - accuracy: 0.8853 - val_loss: 0.5353 - val_accuracy: 0.8370\n","Epoch 74/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3678 - accuracy: 0.8826 - val_loss: 0.5358 - val_accuracy: 0.8406\n","Epoch 75/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3654 - accuracy: 0.8842 - val_loss: 0.5305 - val_accuracy: 0.8405\n","Epoch 76/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3540 - accuracy: 0.8877 - val_loss: 0.5269 - val_accuracy: 0.8426\n","Epoch 77/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3569 - accuracy: 0.8852 - val_loss: 0.5340 - val_accuracy: 0.8407\n","Epoch 78/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3478 - accuracy: 0.8885 - val_loss: 0.5233 - val_accuracy: 0.8440\n","Epoch 79/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3482 - accuracy: 0.8889 - val_loss: 0.5395 - val_accuracy: 0.8419\n","Epoch 80/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3378 - accuracy: 0.8937 - val_loss: 0.5248 - val_accuracy: 0.8422\n","Epoch 81/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3318 - accuracy: 0.8947 - val_loss: 0.5328 - val_accuracy: 0.8431\n","Epoch 82/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3363 - accuracy: 0.8921 - val_loss: 0.5427 - val_accuracy: 0.8406\n","Epoch 83/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3288 - accuracy: 0.8954 - val_loss: 0.5287 - val_accuracy: 0.8480\n","Epoch 84/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3214 - accuracy: 0.8991 - val_loss: 0.5341 - val_accuracy: 0.8450\n","Epoch 85/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3247 - accuracy: 0.8976 - val_loss: 0.5194 - val_accuracy: 0.8481\n","Epoch 86/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3235 - accuracy: 0.8965 - val_loss: 0.5457 - val_accuracy: 0.8387\n","Epoch 87/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3226 - accuracy: 0.8978 - val_loss: 0.5366 - val_accuracy: 0.8440\n","Epoch 88/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3122 - accuracy: 0.9030 - val_loss: 0.5217 - val_accuracy: 0.8458\n","Epoch 89/100\n","782/782 [==============================] - 8s 11ms/step - loss: 0.3100 - accuracy: 0.9049 - val_loss: 0.5197 - val_accuracy: 0.8478\n","Epoch 90/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3077 - accuracy: 0.9035 - val_loss: 0.5239 - val_accuracy: 0.8490\n","Epoch 91/100\n","782/782 [==============================] - 9s 11ms/step - loss: 0.3098 - accuracy: 0.9045 - val_loss: 0.5270 - val_accuracy: 0.8445\n","Epoch 92/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3047 - accuracy: 0.9042 - val_loss: 0.5135 - val_accuracy: 0.8548\n","Epoch 93/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.2961 - accuracy: 0.9092 - val_loss: 0.5393 - val_accuracy: 0.8476\n","Epoch 94/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.2975 - accuracy: 0.9078 - val_loss: 0.5187 - val_accuracy: 0.8514\n","Epoch 95/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.3037 - accuracy: 0.9049 - val_loss: 0.5179 - val_accuracy: 0.8521\n","Epoch 96/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.2954 - accuracy: 0.9084 - val_loss: 0.5218 - val_accuracy: 0.8536\n","Epoch 97/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.2990 - accuracy: 0.9067 - val_loss: 0.5259 - val_accuracy: 0.8511\n","Epoch 98/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.2868 - accuracy: 0.9115 - val_loss: 0.5340 - val_accuracy: 0.8491\n","Epoch 99/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.2821 - accuracy: 0.9116 - val_loss: 0.5224 - val_accuracy: 0.8526\n","Epoch 100/100\n","782/782 [==============================] - 8s 10ms/step - loss: 0.2866 - accuracy: 0.9100 - val_loss: 0.5439 - val_accuracy: 0.8519\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"k2htzWA_qv5q"},"source":["##6. Conclusion ##\n","We found out that this task is too complex for using of simple Neural Networks,\n","so after results it was decided to use CNN. The first version of model was without BatchNormalization, Dropout and other features. Therefore, it was predictable that overtraining would become a problem. After adding them we achieved solid result of 91% accuracy on training and 85% accuracy on validation. Thus, we can say that CNN is quite useful for such tasks that are connected with image classification. "]}]}